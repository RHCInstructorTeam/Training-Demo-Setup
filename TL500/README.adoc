= {subject}
:subject: TL500 Demo Setup
:description:  Setup Guide for Instructor Demos
Travis Michette <tmichett@redhat.com>
:doctype: book
:customer:  GLS
:listing-caption: Listing
:toc:
:toclevels: 7
:sectnums:
:sectnumlevels: 6
:numbered:
:chapter-label:
:pdf-page-size: LETTER
:icons: font
ifdef::backend-pdf[]
:title-page-background-image: image:images/Training_Cover.png[pdfwidth=8.0in,position=top left]
:pygments-style: tango
:source-highlighter: pygments
endif::[]
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:revnumber: 1.0

= Setting up a System for Delivering a TL500

== SSH Setup

There is a single playbook provided called *SSH_Config_Setup.yml*. This playbook can be run for locally hosted, nested, KVM foundations or it can be used with the ROLE/RHLS/VT environment.

.Variables for Playbook
[source,yaml]
----
  vars:
#    linux_username: travis  ### This variable is so that you can create the demo configuration for a user other than the Ansible User
## Course SKU Only Valid when using RHU Role courses / Not valid for RHLS
    course_sku: rh999 <1>
    ROLE_IP: 150.239.52.xx <2>
## Delivery Type Options VT, KVM, ROLE ##
    delivery_type: KVM <3>
## IP Addresses for VT or KVM courses
    kvm_host_ip: 192.168.1.123  # IP Address for KVM Host (initial connection machine) <4>
    kvm_foundation_ip: 192.168.122.71   # IP Address attached to NIC2 that is available on the "Externally configured NIC for F0" <5>
    classroom_ip: "{{ ROLE_IP }}" <6>
----
<1> Course SKU. Creates a complete SSH config file for all systems in the course.
<2> Classroom IP address provided from the ROLE/RHLS/VT interface. This is the public IP address you will be connecting to via SSH.
<3> Type of delivery. *KVM*, *ROLE*, or *VT* and controls what files the playbook creates.
<4> Used only for KVM deployments and is the "Physical Address" of the KVM host. This sets up the KVM host as a JumpBox to your nested Foundation0 on the KVM shared/NAT network for the secondary Internet facing NIC presented to the Foundation0 system.
<5> Used only for KVM deployments and is the IP address provided by the *rht-external --status* command.
<6> Recycles the *ROLE_IP* address for use in deployed template files to keep variable names nice.

The playbook should be capable of running on all Linux distributions as well as MacOS. It has only been tested on Fedora, Red Hat, and MacOS.

.Setting Variables and Updating *ansible.cfg*
[IMPORTANT]
======
It is important to setup variables in the playbook prior to running. It is equally important to make any changes and adjustments to the *ansible.cfg* and other adjustments to the playbook.
======

.SSH Keys Required
[WARNING]
======
The playbook sets up SSH configuration files which are required for connection to remote systems. Currently these files rely on SSH keys with specific key names.

* *gls_instructor_id_rsa* - The *id_rsa* key located on Foundation0.
* *lab_rsa* - The *lab_rsa* key located on the workstation system.

It will be necessary to grab these files and place in *~/.ssh* with the appropriate permissions and name in order for the playbook to run.
======

=== Setting up the VT Demonstration Connection

This is the most common type of setup. It will also be the easiest for teaching and delivering VT courses as the playbook can be run multiple times to setup configuration files for all students and the instructor machine.

. Modify the playbook with the *ROLE_IP* variable.

. Set the *delivery_type* variable to be *VT*.

. Execute the playbook using *ansible-playbook SSH_Config_Setup.yml*.
+
[source,bash]
----
[travis@fedora Ansible_Playbooks]$ ansible-playbook SSH_Config_Setup.yml
BECOME password:

PLAY [Setup System for Github with Tools] ********************************************

TASK [Gathering Facts] ***************************************************************
ok: [localhost]

TASK [Create SSH Config.D Directory] *************************************************
ok: [localhost]

TASK [Create SSH Course File for ROLE] ***********************************************
skipping: [localhost]

TASK [Create SSH Course File for KVM] ************************************************
skipping: [localhost]

TASK [Create SSH Course File for VT] *************************************************
ok: [localhost]

TASK [Perform Touch on File to Ensure it Exists] *************************************
changed: [localhost]

TASK [Update SSH Config] *************************************************************
ok: [localhost]

PLAY RECAP ***************************************************************************
localhost                  : ok=5    changed=1    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0
----

=== Setting up the KVM Demonstration Connection

. Modify the playbook with the *kvm_foundation_ip* variable and the *kvm_host_ip* variable.

. Set the *delivery_type* variable to be *KVM*.

. Execute the playbook using *ansible-playbook SSH_Config_Setup.yml*.

=== Setting up the ROLE Demonstration Connection

. Modify the playbook with the *course_sku* variable and the *ROLE_IP* variable.

. Set the *delivery_type* variable to be *ROLE*.

. Execute the playbook using *ansible-playbook SSH_Config_Setup.yml*.

== Accessing the systems via SSH

Depending on whether you are using KVM, ROLE, or VT access, the SSH commands and capabilities for connecting will be different based on the playbook and configuration files generated.

.KVM Hosted VMs

. Use SSH to connect to the workstation VM only *kvm_workstation*.
+
[source,bash]
----
[travis@fedora ~]$ ssh kvm_workstation
----

.VT Hosted VMs

. Use SSH to connect to the workstation VM only *workstation-vt*.
+
[source,bash]
----
[travis@fedora ~]$ ssh workstation-vt
----

.ROLE/RHLS Hosted VMs

This is the only deployment scenario where you can SSH to other VMs directly. For this to work, it is 100% needed that you place *ROLE* as deployment type and that all VMs have been defined in the *Templates/SSH_Config.j2* file. Most all VMs have been created and defined, however, for new courses, it is possible to update the JINJA2 template with the newer VMs.

. Use SSH to connect to the workstation or any other VM using *SKU_<machine_name>*
+
[source,bash]
----
[travis@fedora ~]$ ssh rh124_workstation
----

.Connecting to Other Systems
[TIP]
======
It is possible in the example above to substitute *workstation* with any other VM in the classroom environment.

* servera
* serverb
* serverc
* hub
* controller
* *... and more ...*
======

.Accessing Student Systems
[NOTE]
======
It is possible to run the playbook multiple times for a course delivery to get all students setup so that those systems can be accessed remotely as an instructor.

Once the initial instructor VMs have been setup by setting the IP, SKU, and deployment type as ROLE, the playbooks can be re-run with the *-e* options to setup various students.

.Setting up a Student set of VMs for Instructor Access
[source,bash]
----
ansible-playbook SSH_Config_Setup.yml -e "ROLE_IP=150.75.250.26" -e "course_sku=yoda" <1>
----
<1> In this instance, *yoda* is the name of the student user.

This will create a new config file in *~/.ssh/config.d/yoda.conf* as shown below.

[source,bash]
----
[travis@fedora Ansible_Playbooks]$ cat ~/.ssh/config.d/yoda.conf
Host yoda_*
  StrictHostKeyChecking no
  ForwardAgent yes
  ForwardX11 no
  PreferredAuthentications publickey
  IdentityFile ~/.ssh/lab_rsa

Host yoda_classroom
  User instructor
  Hostname 150.75.250.26
  IdentityFile ~/.ssh/gls_instructor_id_rsa
  Port 22022

Host yoda_bastion
  Hostname 172.25.252.1
  User student
  ProxyJump yoda_classroom

Host yoda_workstation
  Hostname workstation
  User student
  ProxyJump yoda_bastion
----

Now it is possible to SSH directly to student systems using the *<student_name>_<machine_name>* format as shown below.

[source,bash]
----
[travis@fedora ~]$ ssh yoda_workstation
----
======

.SSH Cleanup Files
[WARNING]
======
It is especially important to cleanup old SSH configuration files (especially when creating them for various students). Running the playbooks based on the instructions above should re-write and update any configuration changes provided that for ROLE deployment, you choose to use SKU representation the same. It is recommended to use *lowercase* for the SKU.
======



== TL500 Specific Setup

The regular SSH demo 

. Create SSHuttle connection
.. Use the *--ns=172.25.250.9* option for DNS forwarding
.. Add the OCP Subnet as a subnet to be forwarding over the SSHuttle connection
+
[source,bash]
----
[tmichett@tmichett TL500]$ sshuttle --dns -vr student@workstation-vt 172.0.0.0/8 192.168.50.0/24 10.82.1.0/24 --ns=172.25.250.9
----
+
.SSHuttle Configuration
[IMPORTANT]
======
It is important to get the IP address of the OCP Cluster. In the example above, the way to optain the IP address was to ping the OCP console URL. The IP was in the *10.82.1.0/24* subnet, so it must be added to the *SSHuttle* command line. The DNS server must be specified to be the IP address of the Workstation VM with the *--ns=172.25.250.9* option added to the command line.

======

. Install the OCP CA Certificate from Red Hat Training 
+
[source,bash]
----
$ ./update_certs.sh 
Notice: Trust flag u is set automatically if the private key is present.
Notice: Trust flag u is set automatically if the private key is present.
----

. Open the Console and the CodeReady Workspace

